{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load('/home/mcarroll/Documents/cd-2/humanoid_tracking/whole_body_tracking/logs/rsl_rl/g1_flat/2025-08-26_10-49-04_lefan_walk/collection/v2/0.0/robot_sa_dataset_r5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = data[0]['motion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/mcarroll/Documents/cd-2/humanoid_tracking/whole_body_tracking/MDM')\n",
    "from data_loaders.dataset import extract_observation_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_attention_mask(sequence_type_array):\n",
    "    \"\"\"\n",
    "    Creates a custom attention mask for a sequence of actions and states.\n",
    "\n",
    "    Args:\n",
    "        sequence_type_array (list or torch.Tensor): A boolean array where \n",
    "                                                     True indicates a state and False indicates an action.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The custom attention mask of shape (seq_len, seq_len).\n",
    "\n",
    "\n",
    "    A0 [[ True, False, False, False, False, False],\n",
    "    S0  [ True,  True, False, False, False, False],\n",
    "    A1  [ True,  True,  True, False, False, False],\n",
    "    S1  [ True,  True,  True,  True, False, False],\n",
    "    A2  [ True,  True,  True,  True,  True, False],\n",
    "    S2  [ True,  True,  True,  True,  True,  True]]\n",
    "          A0     S0     A1     S1     A2     S2  \n",
    "    \"\"\"\n",
    "    seq_len = len(sequence_type_array)\n",
    "    is_state = torch.tensor(sequence_type_array, dtype=torch.bool)\n",
    "    \n",
    "    # Start with a standard causal mask (tril) to prevent attending to future elements\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool))\n",
    "\n",
    "\n",
    "\n",
    "    # Apply the custom rules\n",
    "    for i in range(seq_len):\n",
    "        if is_state[i]:\n",
    "            # If the current token is a state, it can attend to all other states.\n",
    "            # This logic needs to override the causal mask for other states.\n",
    "            # A state at index i can attend to any state j, regardless of j's position.\n",
    "            state_indices = torch.where(is_state)[0]\n",
    "            action_indices = torch.where(~is_state)[0]\n",
    "            mask[i, state_indices] = True\n",
    "            mask[i, action_indices] = False\n",
    "        else:\n",
    "            # If the current token is an action, it can only attend to\n",
    "            # past actions and past/current states (this is handled by the tril mask).\n",
    "            pass # The initial causal mask is sufficient here.\n",
    "\n",
    "    return ~mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True],\n",
       "        [ True, False,  True, False,  True, False],\n",
       "        [False, False, False,  True,  True,  True],\n",
       "        [ True, False,  True, False,  True, False],\n",
       "        [False, False, False, False, False,  True],\n",
       "        [ True, False,  True, False,  True, False]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_causal_attention_mask([False, True, False, True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isaaclab3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
